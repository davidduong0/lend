{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lists of vars and printing out some list sizes...\n",
      "75\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import pickle\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "# import statsmodels.api as sm\n",
    "from xgboost import XGBClassifier\n",
    "#import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from datetime import datetime \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "# from shapely import wkt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lists# Long-ass lists of vars etc. (keep in same folder)\n",
    "\n",
    "%matplotlib inline\n",
    "%run lists.py\n",
    "\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPATH = \"/Users/david.duong/dev/lending-club/\"\n",
    "FNAME= \"loans_to_score_2020a.csv\"\n",
    "QAFNAME = \"qavals.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 122)\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv(FPATH + FNAME)\n",
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data QA and clean up \n",
    "(no feature eng/ missing impute yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Numeric Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that all vars is there...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PASS'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_var_is_there(dat, varlist):\n",
    "    print(\"Check that all vars is there...\")\n",
    "    for col in varlist:\n",
    "        if col not in dat.columns: \n",
    "            print(\"Found some column not in train, e.g. \", col)\n",
    "            return \"FAIL\"    \n",
    "    return \"PASS\"\n",
    "        \n",
    "check_var_is_there(dat, numeric_cols_4_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Processing: convert str into numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check missingness after converting to float: \n",
      "loan_amnt                          0\n",
      "int_rate                           0\n",
      "installment                        0\n",
      "annual_inc                         0\n",
      "acc_now_delinq                     0\n",
      "acc_open_past_24mths               0\n",
      "bc_open_to_buy                     1\n",
      "percent_bc_gt_75                   1\n",
      "bc_util                            1\n",
      "dti                                0\n",
      "delinq_2yrs                        0\n",
      "delinq_amnt                        0\n",
      "fico_range_low                     0\n",
      "fico_range_high                    0\n",
      "inq_last_6mths                     0\n",
      "mths_since_last_delinq            31\n",
      "mths_since_last_record            39\n",
      "mths_since_recent_inq              6\n",
      "mths_since_recent_revol_delinq    37\n",
      "mths_since_recent_bc               1\n",
      "mort_acc                           0\n",
      "open_acc                           0\n",
      "pub_rec                            0\n",
      "total_bal_ex_mort                  0\n",
      "revol_bal                          0\n",
      "revol_util                         0\n",
      "total_bc_limit                     0\n",
      "total_acc                          0\n",
      "total_il_high_credit_limit         0\n",
      "num_rev_accts                      0\n",
      "mths_since_recent_bc_dlq          40\n",
      "pub_rec_bankruptcies               0\n",
      "num_accts_ever_120_pd              0\n",
      "chargeoff_within_12_mths           0\n",
      "collections_12_mths_ex_med         0\n",
      "tax_liens                          0\n",
      "mths_since_last_major_derog       43\n",
      "num_sats                           0\n",
      "num_tl_op_past_12m                 0\n",
      "mo_sin_rcnt_tl                     0\n",
      "tot_hi_cred_lim                    0\n",
      "tot_cur_bal                        0\n",
      "avg_cur_bal                        0\n",
      "num_bc_tl                          0\n",
      "num_actv_bc_tl                     0\n",
      "num_bc_sats                        0\n",
      "pct_tl_nvr_dlq                     0\n",
      "num_tl_90g_dpd_24m                 0\n",
      "num_tl_30dpd                       0\n",
      "num_tl_120dpd_2m                   2\n",
      "num_il_tl                          0\n",
      "mo_sin_old_il_acct                 0\n",
      "num_actv_rev_tl                    0\n",
      "mo_sin_old_rev_tl_op               0\n",
      "mo_sin_rcnt_rev_tl_op              0\n",
      "total_rev_hi_lim                   0\n",
      "num_rev_tl_bal_gt_0                0\n",
      "num_op_rev_tl                      0\n",
      "tot_coll_amt                       0\n",
      "annual_inc_joint                  47\n",
      "dti_joint                         47\n",
      "open_acc_6m                        0\n",
      "open_act_il                        0\n",
      "open_il_12m                        0\n",
      "open_il_24m                        0\n",
      "mths_since_rcnt_il                 0\n",
      "total_bal_il                       0\n",
      "il_util                            8\n",
      "open_rv_12m                        0\n",
      "open_rv_24m                        0\n",
      "max_bal_bc                         0\n",
      "all_util                           0\n",
      "inq_fi                             0\n",
      "total_cu_tl                        0\n",
      "inq_last_12m                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def find_non_numeric_vars(dat, varlist):\n",
    "    dtypes_dict = dat[varlist].dtypes\n",
    "    non_numeric_list = [col for col in varlist if dtypes_dict[col] not in (['int64', 'float64'])]\n",
    "    set_of_non_numeric_types = set(dat[non_numeric_list].dtypes)\n",
    "    #print(\"Set of data types in potential to-convert list: \", set_of_non_numeric_types)\n",
    "    if len(set_of_non_numeric_types) > 1:\n",
    "        raise ValueError(\"There are potentially some unrecognized types (e.g. non-object (non-string) types)!!\")\n",
    "    return non_numeric_list\n",
    "\n",
    "def util_str_to_numeric(instr):\n",
    "    try:\n",
    "        return float(instr)# Note: This can take out the spaces e.g. \" .95  \" can be converted no problem\n",
    "    except:\n",
    "        stripped = instr.strip()\n",
    "        if len(stripped) == 0 or stripped == \"null\":# i.e. instr is an empty string of any length\n",
    "            return np.nan# Note that np.nan is not = np.nan, but np.isnan(np.nan) is True\n",
    "            # Also note that later we will impute the missings for these vars so we shouldn't be doing that now\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognize Non-numeric string values, don't know how to convert: \", instr)\n",
    "        \n",
    "def apply_convert_non_numeric(dat, nn_varlist):\n",
    "    cdat = dat.copy()\n",
    "    for var in dat[nn_varlist]:\n",
    "        cdat[var] = cdat[var].apply(util_str_to_numeric)\n",
    "    return cdat\n",
    "        \n",
    "non_numeric_vars = find_non_numeric_vars(dat, numeric_cols_4_model)\n",
    "dat = apply_convert_non_numeric(dat, non_numeric_vars)\n",
    "\n",
    "print(\"Check missingness after converting to float: \")\n",
    "print(dat[numeric_cols_4_model].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main QA: Review distribution and compare to old (train) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "# Remove this def later to move to utils.py\n",
    "# TODO 01/11/20: Write func to turn var into continuous first\n",
    "# TODO: The below np.nanpercentile will NOT WORK if I still have string vars okay?\n",
    "\n",
    "def get_cont_distribution_dict(dat, varlist=[], filter_ys = None):\n",
    "    \"\"\"filter is None or a list of years\"\"\"\n",
    "    # Temp: Check distribution of vars\n",
    "    if filter_ys != None:# If there's a filter     \n",
    "        dat = dat[dat['issue_year'].isin(filter_ys)]\n",
    "    \n",
    "    tempdict = {}    \n",
    "    for col in varlist:\n",
    "        tempdict[col] = {}\n",
    "    \n",
    "    for col in varlist:\n",
    "        tempdict[col]['min'] = np.nanmin(dat[col].values)\n",
    "        tempdict[col]['max'] = np.nanmax(dat[col].values)\n",
    "        tempdict[col]['95th'] = np.nanpercentile(dat[col].values, 95)\n",
    "    print(len(tempdict))\n",
    "    return tempdict\n",
    "\n",
    "def check_vars_within_min_max(dat, varlist, dict0, dict1):\n",
    "    list_not_working = []\n",
    "    for col in varlist:\n",
    "        try:\n",
    "            if dict1['continuous'][col]['min'] < dict0['continuous'][col]['min']:\n",
    "                print(\"Val lower than min: \", col, dict1['continuous'][col]['min'], dict0['continuous'][col]['min'])\n",
    "            elif dict1['continuous'][col]['max'] > dict0['continuous'][col]['max']:\n",
    "                print(\"Val greater than max: \", col, dict1['continuous'][col]['max'], \"vs. \", dict0['continuous'][col]['max'])\n",
    "            else:\n",
    "                print(col, \"[ok]\")\n",
    "        except:\n",
    "            list_not_working.append(col)\n",
    "            print(\"Cannot compare for col \", col)\n",
    "            print(\"Distrb (new vs. existing): \", dict1['continuous'][col], dict0['continuous'][col])\n",
    "    if len(list_not_working) > 0:\n",
    "        raise ValueError(\"Some vars still not comparable between new and old data: \", list_not_working)\n",
    "\n",
    "def check_vars_with_abnormally_high_values(dat, varlist, dict0, dict1):\n",
    "    for col in varlist:\n",
    "        try:\n",
    "            m1 = dict1['continuous'][col]['max']\n",
    "            h0 = dict0['continuous'][col]['95th']\n",
    "            if m1 > h0:\n",
    "                print(\"Max Val greater than 95th: Max \", col, dict1['continuous'][col]['max'], \"vs. \", dict0['continuous'][col]['95th'])\n",
    "                if m1 > 2 * h0:\n",
    "                    print(\"!!!! HEAVY WARNING: More than double!!!\\n\")\n",
    "            else:\n",
    "                print(col, \"[ok]\")\n",
    "        except:\n",
    "            raise ValueError(\"Hmm, still cannot compare\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val greater than max:  loan_amnt 40000.0 vs.  35000.0\n",
      "int_rate [ok]\n",
      "installment [ok]\n",
      "annual_inc [ok]\n",
      "acc_now_delinq [ok]\n",
      "acc_open_past_24mths [ok]\n",
      "bc_open_to_buy [ok]\n",
      "percent_bc_gt_75 [ok]\n",
      "bc_util [ok]\n",
      "dti [ok]\n",
      "delinq_2yrs [ok]\n",
      "delinq_amnt [ok]\n",
      "fico_range_low [ok]\n",
      "fico_range_high [ok]\n",
      "inq_last_6mths [ok]\n",
      "mths_since_last_delinq [ok]\n",
      "mths_since_last_record [ok]\n",
      "mths_since_recent_inq [ok]\n",
      "mths_since_recent_revol_delinq [ok]\n",
      "mths_since_recent_bc [ok]\n",
      "mort_acc [ok]\n",
      "open_acc [ok]\n",
      "pub_rec [ok]\n",
      "total_bal_ex_mort [ok]\n",
      "revol_bal [ok]\n",
      "revol_util [ok]\n",
      "total_bc_limit [ok]\n",
      "total_acc [ok]\n",
      "total_il_high_credit_limit [ok]\n",
      "num_rev_accts [ok]\n",
      "mths_since_recent_bc_dlq [ok]\n",
      "pub_rec_bankruptcies [ok]\n",
      "num_accts_ever_120_pd [ok]\n",
      "chargeoff_within_12_mths [ok]\n",
      "collections_12_mths_ex_med [ok]\n",
      "tax_liens [ok]\n",
      "mths_since_last_major_derog [ok]\n",
      "num_sats [ok]\n",
      "num_tl_op_past_12m [ok]\n",
      "mo_sin_rcnt_tl [ok]\n",
      "tot_hi_cred_lim [ok]\n",
      "tot_cur_bal [ok]\n",
      "avg_cur_bal [ok]\n",
      "num_bc_tl [ok]\n",
      "num_actv_bc_tl [ok]\n",
      "num_bc_sats [ok]\n",
      "pct_tl_nvr_dlq [ok]\n",
      "num_tl_90g_dpd_24m [ok]\n",
      "num_tl_30dpd [ok]\n",
      "num_tl_120dpd_2m [ok]\n",
      "num_il_tl [ok]\n",
      "mo_sin_old_il_acct [ok]\n",
      "num_actv_rev_tl [ok]\n",
      "mo_sin_old_rev_tl_op [ok]\n",
      "mo_sin_rcnt_rev_tl_op [ok]\n",
      "total_rev_hi_lim [ok]\n",
      "num_rev_tl_bal_gt_0 [ok]\n",
      "num_op_rev_tl [ok]\n",
      "tot_coll_amt [ok]\n",
      "annual_inc_joint [ok]\n",
      "dti_joint [ok]\n",
      "open_acc_6m [ok]\n",
      "open_act_il [ok]\n",
      "open_il_12m [ok]\n",
      "open_il_24m [ok]\n",
      "mths_since_rcnt_il [ok]\n",
      "total_bal_il [ok]\n",
      "il_util [ok]\n",
      "open_rv_12m [ok]\n",
      "open_rv_24m [ok]\n",
      "max_bal_bc [ok]\n",
      "all_util [ok]\n",
      "inq_fi [ok]\n",
      "total_cu_tl [ok]\n",
      "inq_last_12m [ok]\n"
     ]
    }
   ],
   "source": [
    "# i. Get distribution\n",
    "#get_distribution_dict = utils.get_distribution_dict# Restore this later\n",
    "distribution_dict = {'continuous':{}, 'cat':{}}\n",
    "distribution_dict['continuous'] = get_cont_distribution_dict(dat, varlist = numeric_cols_4_model)\n",
    "qavals_dict = pickle.load(open(FPATH + QAFNAME, \"rb\"))\n",
    "\n",
    "# ii. Compare min-max to old data:\n",
    "check_vars_within_min_max(dat, numeric_cols_4_model, qavals_dict, distribution_dict)    \n",
    "\n",
    "# iii. Compare max to high percentile e.g. 95th in old data:\n",
    "check_vars_with_abnormally_high_values(dat, numeric_cols_4_model, qavals_dict, distribution_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Val greater than 95th: Max  loan_amnt 40000.0 vs.  30000.0\n",
      "Max Val greater than 95th: Max  int_rate 25.65 vs.  17.86\n",
      "Max Val greater than 95th: Max  installment 1336.23 vs.  982.02\n",
      "Max Val greater than 95th: Max  annual_inc 300000.0 vs.  155000.0\n",
      "acc_now_delinq [ok]\n",
      "Max Val greater than 95th: Max  acc_open_past_24mths 15 vs.  10.0\n",
      "Max Val greater than 95th: Max  bc_open_to_buy 91372.0 vs.  37627.399999999965\n",
      "!!!! HEAVY WARNING: More than double!!!\n",
      "\n",
      "percent_bc_gt_75 [ok]\n",
      "Max Val greater than 95th: Max  bc_util 99.7 vs.  98.2\n",
      "Max Val greater than 95th: Max  dti 48.49 vs.  33.71\n",
      "Max Val greater than 95th: Max  delinq_2yrs 4 vs.  2.0\n",
      "delinq_amnt [ok]\n",
      "fico_range_low [ok]\n",
      "fico_range_high [ok]\n",
      "inq_last_6mths [ok]\n",
      "Max Val greater than 95th: Max  mths_since_last_delinq 76.0 vs.  74.0\n",
      "Max Val greater than 95th: Max  mths_since_last_record 118.0 vs.  113.0\n",
      "Max Val greater than 95th: Max  mths_since_recent_inq 23.0 vs.  19.0\n",
      "Max Val greater than 95th: Max  mths_since_recent_revol_delinq 82.0 vs.  75.0\n",
      "Max Val greater than 95th: Max  mths_since_recent_bc 160.0 vs.  92.0\n",
      "mort_acc [ok]\n",
      "Max Val greater than 95th: Max  open_acc 34 vs.  22.0\n",
      "pub_rec [ok]\n",
      "Max Val greater than 95th: Max  total_bal_ex_mort 169315 vs.  130658.75\n",
      "Max Val greater than 95th: Max  revol_bal 115251.0 vs.  44503.75\n",
      "!!!! HEAVY WARNING: More than double!!!\n",
      "\n",
      "Max Val greater than 95th: Max  revol_util 99.7 vs.  91.8\n",
      "Max Val greater than 95th: Max  total_bc_limit 102100 vs.  63300.0\n",
      "Max Val greater than 95th: Max  total_acc 73 vs.  47.0\n",
      "Max Val greater than 95th: Max  total_il_high_credit_limit 133517 vs.  116559.5\n",
      "Max Val greater than 95th: Max  num_rev_accts 49 vs.  30.0\n",
      "Max Val greater than 95th: Max  mths_since_recent_bc_dlq 82.0 vs.  77.0\n",
      "pub_rec_bankruptcies [ok]\n",
      "Max Val greater than 95th: Max  num_accts_ever_120_pd 7 vs.  3.0\n",
      "!!!! HEAVY WARNING: More than double!!!\n",
      "\n",
      "chargeoff_within_12_mths [ok]\n",
      "collections_12_mths_ex_med [ok]\n",
      "tax_liens [ok]\n",
      "mths_since_last_major_derog [ok]\n",
      "Max Val greater than 95th: Max  num_sats 34 vs.  22.0\n",
      "Max Val greater than 95th: Max  num_tl_op_past_12m 9 vs.  6.0\n",
      "Max Val greater than 95th: Max  mo_sin_rcnt_tl 88 vs.  23.0\n",
      "!!!! HEAVY WARNING: More than double!!!\n",
      "\n",
      "Max Val greater than 95th: Max  tot_hi_cred_lim 858918 vs.  484908.75\n",
      "Max Val greater than 95th: Max  tot_cur_bal 738516 vs.  418468.5\n",
      "Max Val greater than 95th: Max  avg_cur_bal 67138 vs.  40962.0\n",
      "Max Val greater than 95th: Max  num_bc_tl 26 vs.  17.0\n",
      "Max Val greater than 95th: Max  num_actv_bc_tl 11 vs.  8.0\n",
      "Max Val greater than 95th: Max  num_bc_sats 16 vs.  10.0\n",
      "pct_tl_nvr_dlq [ok]\n",
      "num_tl_90g_dpd_24m [ok]\n",
      "num_tl_30dpd [ok]\n",
      "num_tl_120dpd_2m [ok]\n",
      "Max Val greater than 95th: Max  num_il_tl 40 vs.  23.0\n",
      "Max Val greater than 95th: Max  mo_sin_old_il_acct 253 vs.  214.0\n",
      "Max Val greater than 95th: Max  num_actv_rev_tl 18 vs.  12.0\n",
      "Max Val greater than 95th: Max  mo_sin_old_rev_tl_op 416 vs.  371.0\n",
      "Max Val greater than 95th: Max  mo_sin_rcnt_rev_tl_op 91 vs.  45.0\n",
      "!!!! HEAVY WARNING: More than double!!!\n",
      "\n",
      "Max Val greater than 95th: Max  total_rev_hi_lim 205700 vs.  86700.0\n",
      "!!!! HEAVY WARNING: More than double!!!\n",
      "\n",
      "Max Val greater than 95th: Max  num_rev_tl_bal_gt_0 18 vs.  12.0\n",
      "Max Val greater than 95th: Max  num_op_rev_tl 30 vs.  17.0\n",
      "Max Val greater than 95th: Max  tot_coll_amt 2147 vs.  907.0\n",
      "!!!! HEAVY WARNING: More than double!!!\n",
      "\n",
      "Max Val greater than 95th: Max  annual_inc_joint 222000.0 vs.  185000.0\n",
      "dti_joint [ok]\n",
      "Max Val greater than 95th: Max  open_acc_6m 7 vs.  3.0\n",
      "!!!! HEAVY WARNING: More than double!!!\n",
      "\n",
      "Max Val greater than 95th: Max  open_act_il 10 vs.  9.0\n",
      "Max Val greater than 95th: Max  open_il_12m 4 vs.  2.0\n",
      "Max Val greater than 95th: Max  open_il_24m 7 vs.  5.0\n",
      "Max Val greater than 95th: Max  mths_since_rcnt_il 112 vs.  87.0\n",
      "Max Val greater than 95th: Max  total_bal_il 150103.0 vs.  106563.54999999996\n",
      "il_util [ok]\n",
      "Max Val greater than 95th: Max  open_rv_12m 6 vs.  4.0\n",
      "Max Val greater than 95th: Max  open_rv_24m 10 vs.  8.0\n",
      "Max Val greater than 95th: Max  max_bal_bc 20400.0 vs.  15336.249999999993\n",
      "all_util [ok]\n",
      "Max Val greater than 95th: Max  inq_fi 5 vs.  4.0\n",
      "Max Val greater than 95th: Max  total_cu_tl 20 vs.  7.0\n",
      "!!!! HEAVY WARNING: More than double!!!\n",
      "\n",
      "Max Val greater than 95th: Max  inq_last_12m 9 vs.  7.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply feature engineers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 76)\n"
     ]
    }
   ],
   "source": [
    "def feature_engineer_numeric_vars(df, numeric_vars):\n",
    "    \"\"\"This takes numeric vars and process them (fill missings) then outputs that list with features only\"\"\"\n",
    "    return df[['id'] + numeric_vars].fillna(0)# Note btw that id doesn't have missing so it won't be filled w any 0s\n",
    "\n",
    "numeric_post_fe_df = feature_engineer_numeric_vars(dat, numeric_cols_4_model)\n",
    "print(numeric_post_fe_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
